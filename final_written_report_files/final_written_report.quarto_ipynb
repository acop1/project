{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"final report\"\n",
        "author: \"Aneesh & Ken\"\n",
        "format: html\n",
        "editor: visual\n",
        "---\n",
        "\n",
        "\n",
        "FINAL WRITTEN REPORT\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## **Introduction**\n",
        "\n",
        "The Rugby World Cup (RWC) is the most prestigious tournament in men’s international rugby, held every four years and featuring the top-performing nations from around the globe. Since its inception in 1987, all winning teams have come from the group of tier-one rugby nations—those with well-established professional structures and a history of competitive success. The World Cup's high stakes, unique pressure, and knockout format often produce different outcomes from regular international fixtures, yet the path to RWC success may still be written in a team’s performance leading up to the tournament.\n",
        "\n",
        "This project seeks to bridge our understanding of regular international performance with World Cup outcomes through a predictive modeling lens. Our guiding research question is:\\\n",
        "\\> **Can regular fixture performance since 1999 reliably predict World Cup success for tier-one rugby nations?**\n",
        "\n",
        "We expect that teams with consistently high win rates, dominant scoring margins, and strong rankings (e.g., Elo ratings) leading into a World Cup are more likely to progress further or win the tournament. Based on our model, and consistent with historical trends, we predict that **South Africa (RSA)**, **Ireland (IRE)**, or **New Zealand (NZ)** are the most likely candidates to win the 2027 Rugby World Cup.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## **Data**\n",
        "\n",
        "### **Data Source and Collection**\n",
        "\n",
        "The data for this project was sourced from an international rugby match dataset containing results from test matches played by men's national teams. The dataset includes **2,783 matches**, of which **1,230** were retained after filtering for: - Matches played **between 1999 and 2024**, inclusive - **Tier-one teams** only - Complete match records (with no missing scores or team names)\n",
        "\n",
        "### **Cases and Variables**\n",
        "\n",
        "Each row in the dataset represents a single international rugby match and includes variables such as: - `date`: Match date - `home_team`, `away_team`: Competing teams - `home_score`, `away_score`: Points scored by each team - `competition`: Type of match (e.g., World Cup, Six Nations, etc.) - `neutral`: Boolean indicator for neutral venue - `world_cup`: Boolean indicator for whether the match is a World Cup fixture\n",
        "\n",
        "### **Data Wrangling and Feature Engineering**\n",
        "\n",
        "To support our analysis, we created several new variables and tidied the dataset: - Extracted `year` from the match date for time-series analysis - Created binary indicators: `homeWin` and `awayWin` - Calculated `count` to aid in aggregating match totals - Grouped matches by team to calculate: - **Home and away win percentages** - **Average points scored and conceded (home and away)** - **World Cup vs. regular fixture performance** - Developed year-by-year win percentage timelines for each team\n",
        "\n",
        "### **Variables for Modeling**\n",
        "\n",
        "We plan to include the following variables in our predictive models: - **Win Percentage (last 2 years before RWC)**: Measures recent performance - **Average Point Differential**: Offensive and defensive strength indicator - **Elo Rating** (if included or computed): Captures opponent-adjusted team strength - **Tournament Flag**: Helps compare regular matches to World Cup fixtures - **Home/Away Advantage**: Quantified through win rates and score differentials\n",
        "\n",
        "These variables were chosen for their interpretability and demonstrated relevance in differentiating strong and weak tournament performers.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## **Methodology**\n",
        "\n",
        "### **Research Question**\n",
        "\n",
        "Our goal is to explore whether consistent performance in international fixtures since 1999 can predict a team’s success at the Rugby World Cup (RWC). We focus on tier-one nations, and based on trends in both regular and tournament data, we aim to forecast the winner of the 2027 RWC. Our preliminary model predicts that **South Africa, Ireland, or New Zealand** are the most likely champions.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### **Data Overview and Cleaning**\n",
        "\n",
        "We used a dataset containing **2,783 international matches**, which was filtered to: - **Matches after 1998**, yielding **1,230 matches**. - **Tier-one teams only**, excluding matches with insufficient data or unclear team tier.\n",
        "\n",
        "Cleaning Steps: - Extracted **year** from match dates for temporal analysis. - Created binary flags for **homeWin** and **awayWin**. - Dropped rows with missing values. - Created a **\"count\"** variable to aggregate matches played per team.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### **Feature Engineering and Wrangling**\n",
        "\n",
        "We created several new variables from existing match data: - **Home/Away Win Percentages**: Calculated by aggregating match results per team. - **Average Points Scored and Conceded**: For both World Cup and non-World Cup matches. - **World Cup Match Flag**: To compare regular vs. tournament performance. - **Yearly Win Percentage**: A normalized view of performance over time per team.\n",
        "\n",
        "> Code implementation used pandas and NumPy, with seaborn and matplotlib for plotting.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### **Exclusions**\n",
        "\n",
        "We excluded: - All matches involving **non-tier-one nations**. - Matches with **missing scores** or unclear venues. - Non-competitive matches that could skew performance metrics (e.g., experimental squads).\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### **Summary Statistics**\n",
        "\n",
        "| Variable      | Mean   | Std Dev | Min  | Max  |\n",
        "|---------------|--------|---------|------|------|\n",
        "| Home Score    | 25.07  | 13.15   | 0    | 101  |\n",
        "| Away Score    | 20.78  | 11.38   | 0    | 68   |\n",
        "| Home Win Rate | 59.6%  | —       | 0    | 1    |\n",
        "| Away Win Rate | 38.4%  | —       | 0    | 1    |\n",
        "| Year          | 2011.5 | 7.2     | 1999 | 2024 |\n",
        "\n",
        "**Observation**:\\\n",
        "On average, the **home team outperforms the away team by \\~4.3 points**. The home win rate is significantly higher across all teams.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "### **Key Visualizations**\n",
        "\n",
        "**1. Home and Away Win Rates by Team**\n",
        "<img src=\"data:image/png;base64,[image_placeholder]\" alt=\"Win Rate Plot\" />\n"
      ],
      "id": "3e0ace5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from collections import defaultdict\n",
        "import random\n",
        "rugbyDF = pd.read_csv(\"data/rugby.csv\")\n",
        "rugbyDF.shape\n",
        "#(2783, 11)"
      ],
      "id": "f3754e2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#only keeping data after 1999\n",
        "#will create a year col and then trim the data\n",
        "\n",
        "rugbyDF['year'] = rugbyDF['date'].str[0:4].astype(int)\n",
        "rugbyDF = rugbyDF[rugbyDF.year > 1998]\n",
        "rugbyDF.dropna(inplace = True)\n",
        "#new shape of dataframe: (1230,12)"
      ],
      "id": "70c1e17f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#creating variable to track if home or away team won\n",
        "#created weights for win, draw, and loss\n",
        "rugbyDF[\"homeWin\"] = np.where(rugbyDF[\"home_score\"] > rugbyDF[\"away_score\"], 1,0)\n",
        "rugbyDF[\"awayWin\"] = np.where(rugbyDF[\"home_score\"] < rugbyDF[\"away_score\"], 1,0)\n",
        "\n",
        "#creating a count var to help with num of games played later on\n",
        "rugbyDF[\"count\"] = 1"
      ],
      "id": "0da342f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can observe that the mean points scored by the home team was approximately 4.2 higher than the away team. All major quadrants have higher points for home_score than away_score, and the std is also greater.\n",
        "\n",
        "We also notice that the home team won \\~59.6%\\* of the games contested.\n",
        "\n",
        "\\*This does not account for games that take place in neutral venues.\n"
      ],
      "id": "d1bac632"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#create diff df by teams, then find the summary statistics for those teams.\n",
        "unq_hteams = rugbyDF['home_team'].unique()\n",
        "unq_ateams = rugbyDF['away_team'].unique()\n",
        "unq_teams = np.unique((unq_hteams, unq_ateams))\n",
        "\n",
        "#shortens the df to only include awayteam, awaywin or hometeam, homewin\n",
        "rugbyDFH = rugbyDF[[\"home_team\",\"homeWin\",\"count\"]]\n",
        "rugbyDFA = rugbyDF[[\"away_team\",\"awayWin\",\"count\"]]\n",
        "\n",
        "#groups the data by team\n",
        "groupedH = rugbyDFH.groupby('home_team').sum()\n",
        "groupedA = rugbyDFA.groupby('away_team').sum()\n",
        "\n",
        "#renames the axis to the same thing\n",
        "groupedA = groupedA.rename_axis('team')\n",
        "groupedH = groupedH.rename_axis('team')\n",
        "\n",
        "#find team win percentage by away and home \n",
        "groupedH[\"home_win%\"] = groupedH[\"homeWin\"]/groupedH[\"count\"] *100\n",
        "groupedA[\"away_win%\"] = groupedA[\"awayWin\"]/groupedA[\"count\"] *100\n",
        "\n",
        "#renames count so that they dont clash when merging\n",
        "groupedH = groupedH.rename(columns={'count': 'count_home'})\n",
        "groupedA = groupedA.rename(columns={'count': 'count_away'})\n",
        "\n",
        "#merge the data frames\n",
        "teams_wins = pd.merge(groupedH, groupedA, on='team', how='inner')\n",
        "teams_wins"
      ],
      "id": "6e5b50c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This data frame represents the team wise performance breakdown from 1999-2024.\n"
      ],
      "id": "20d98253"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "y = np.arange(len(unq_teams))  # Team positions\n",
        "width = 0.37  # Bar width\n",
        "\n",
        "plt.barh(y - width/2, teams_wins[\"home_win%\"], width, label='Home Win %')\n",
        "plt.barh(y + width/2, teams_wins[\"away_win%\"], width, label='Away Win %')\n",
        "plt.yticks(y, unq_teams)\n",
        "\n",
        "# Add labels and title\n",
        "plt.ylabel('Teams')\n",
        "plt.xlabel('Home Win% and Away Win%')\n",
        "plt.title('Home and Away Win Percentage By Team')\n",
        "\n",
        "plt.legend()\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "60c43bd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- New Zealand dominates both at home and away.\n",
        "- All teams perform **better at home**, confirming home advantage.\n",
        "- Italy underperforms consistently.\n",
        "\n",
        "**2. Average Points Scored vs. Conceded**\n",
        "- Teams like **New Zealand** and **South Africa** show high scores with low concession.\n",
        "- **Italy** and **Scotland** concede more than they score, especially in away games.\n"
      ],
      "id": "def0c8f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#a function to create a scoring dataset\n",
        "def createscoringdataset(rugbyDF):\n",
        "  \n",
        "  #shortens the df to only include awayteam, awaywin or hometeam, homewin\n",
        "  rugbyDFH_score = rugbyDF[[\"home_team\",\"home_score\",\"away_score\",\"count\"]]\n",
        "  rugbyDFA_score = rugbyDF[[\"away_team\",\"away_score\",\"home_score\",\"count\"]]\n",
        "\n",
        "  #renaming away_score and home_score to home_conceded and away_conceded\n",
        "  rugbyDFH_score = rugbyDFH_score.rename(columns={'away_score': 'home_conceded'})\n",
        "  rugbyDFA_score = rugbyDFA_score.rename(columns={'home_score': 'away_conceded'})\n",
        "\n",
        "  #groups the data by team\n",
        "  groupedH_score = rugbyDFH_score.groupby('home_team').sum()\n",
        "  groupedA_score = rugbyDFA_score.groupby('away_team').sum()\n",
        "\n",
        "  #renames the axis to the same thing\n",
        "  groupedH_score = groupedH_score.rename_axis('team')\n",
        "  groupedA_score = groupedA_score.rename_axis('team')\n",
        "\n",
        "  #merge the data frames\n",
        "  teams_score = pd.merge(groupedH_score, groupedA_score, on='team', how='inner')\n",
        "\n",
        "  #rename count_x and count_y to home_played and away_played\n",
        "  teams_score = teams_score.rename(columns={'count_x': 'home_played', 'count_y': 'away_played'})\n",
        "\n",
        "  #find team win percentage by away and home \n",
        "  teams_score[\"home_score_avg\"] = teams_score[\"home_score\"]/teams_score[\"home_played\"]\n",
        "  teams_score[\"away_score_avg\"] = teams_score[\"away_score\"]/teams_score[\"away_played\"]\n",
        "\n",
        "  teams_score[\"home_conceded_avg\"] = teams_score[\"home_conceded\"]/teams_score[\"home_played\"]\n",
        "  teams_score[\"away_conceded_avg\"] = teams_score[\"away_conceded\"]/teams_score[\"away_played\"]\n",
        "  return teams_score\n",
        "\n",
        "teams_score = createscoringdataset(rugbyDF)"
      ],
      "id": "1f317e06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Create a 2x2 grid of subplots\n",
        "fig, axs = plt.subplots(2, 2)  # 2 rows, 2 columns\n",
        "\n",
        "# Add main title\n",
        "fig.suptitle(\"Teamwise Home vs Away Performance\", \n",
        "             fontsize=16, \n",
        "             y=1.02,          # Adjust vertical position (1.0 = top of plot)\n",
        "             fontweight='bold')\n",
        "\n",
        "# Plot 1: Home Win %\n",
        "axs[0, 0].barh(unq_teams, teams_wins[\"home_win%\"], color='blue')\n",
        "axs[0, 0].set_title('Home Win Percentage')\n",
        "axs[0, 0].set_xlabel('Win %')\n",
        "\n",
        "# Plot 2: Away Win %\n",
        "axs[0, 1].barh(unq_teams, teams_wins[\"away_win%\"], color='orange')\n",
        "axs[0, 1].set_title('Away Win Percentage')\n",
        "axs[0, 1].set_xlabel('Win %')\n",
        "\n",
        "# Plot 3: Home vs Away Comparison (side-by-side)\n",
        "y = range(len(unq_teams))\n",
        "width = 0.35\n",
        "axs[1, 0].barh([y - width/2 for y in y], teams_wins[\"home_win%\"], width, label='Home', color='blue')\n",
        "axs[1, 0].barh([y + width/2 for y in y], teams_wins[\"away_win%\"], width, label='Away', color='orange')\n",
        "axs[1, 0].set_title('Home vs Away Comparison')\n",
        "axs[1, 0].set_xlabel('Win %')\n",
        "axs[1, 0].set_yticks(y)\n",
        "axs[1, 0].set_yticklabels(unq_teams)\n",
        "axs[1, 0].legend()\n",
        "\n",
        "# Plot 4: Difference (Home - Away)\n",
        "axs[1, 1].barh(unq_teams, teams_wins[\"home_win%\"] - teams_wins[\"away_win%\"], color='green')\n",
        "axs[1, 1].set_title('Home Advantage (Home - Away)')\n",
        "axs[1, 1].set_xlabel('Win % Difference')\n",
        "\n",
        "plt.tight_layout(rect=[0.00, 0.0, 1, 1]) # Adjusts spacing between subplots\n",
        "plt.subplots_adjust(wspace=0.7, hspace=0.6) \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "45907cae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. World Cup vs. Regular Match Comparison**\n",
        "- **Ireland and South Africa** maintain strong performance in both contexts.\n",
        "- Some teams **drop significantly in performance during World Cups**, revealing tournament pressure or lack of depth.\n"
      ],
      "id": "5135832d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#creates world cup scoring df\n",
        "\n",
        "worldCupDF = rugbyDF[rugbyDF.world_cup == True]\n",
        "nonWorldCup = rugbyDF[rugbyDF.world_cup == False]\n",
        "wc_scoring = createscoringdataset(worldCupDF)\n",
        "non_wc_scoring = createscoringdataset(nonWorldCup)"
      ],
      "id": "f74e403a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Create a 2x2 grid of subplots\n",
        "fig, axs = plt.subplots(2, 2)  # 2 rows, 2 columns\n",
        "\n",
        "# Add main title\n",
        "fig.suptitle(\"World Cup vs Non World Cup Offense and Defense\", \n",
        "             fontsize=16, \n",
        "             y=1.02,          # Adjust vertical position (1.0 = top of plot)\n",
        "             fontweight='bold')\n",
        "\n",
        "# Plot 1: World Cup vs Non World Cup home-score-avg\n",
        "y = range(len(unq_teams))\n",
        "width = 0.35\n",
        "axs[0, 0].barh([y - width/2 for y in y], wc_scoring['home_score_avg'], width, label='World Cup', color='#D4AF37') \n",
        "axs[0, 0].barh([y + width/2 for y in y], non_wc_scoring['home_score_avg'], width, label='Non World Cup', color='#A6A6A6')  \n",
        "axs[0, 0].set_title('Home Points')\n",
        "axs[0, 0].set_xlabel('Avg Points')\n",
        "axs[0, 0].set_yticks(y)\n",
        "axs[0, 0].set_yticklabels(unq_teams)\n",
        "\n",
        "\n",
        "# Plot 2: World Cup vs Non World Cup away-score-avg\n",
        "axs[1, 0].barh([y - width/2 for y in y], wc_scoring['away_score_avg'], width, label='World Cup', color='#D4AF37') \n",
        "axs[1, 0].barh([y + width/2 for y in y], non_wc_scoring['away_score_avg'], width, label='Non World Cup', color='#A6A6A6')  \n",
        "axs[1, 0].set_title('Away Points ')\n",
        "axs[1, 0].set_xlabel('Avg Points')\n",
        "axs[1, 0].set_yticks(y)\n",
        "axs[1, 0].set_yticklabels(unq_teams)\n",
        "\n",
        "\n",
        "# Plot 3: World Cup vs Non World Cup home-conceded-avg\n",
        "axs[0, 1].barh([y - width/2 for y in y], wc_scoring['home_conceded_avg'], width, label='World Cup', color='#D4AF37') \n",
        "axs[0, 1].barh([y + width/2 for y in y], non_wc_scoring['home_conceded_avg'], width, label='Non World Cup', color='#A6A6A6')  \n",
        "axs[0, 1].set_title('Home Conceded ')\n",
        "axs[0, 1].set_xlabel('Avg Points')\n",
        "axs[0, 1].set_yticks(y)\n",
        "axs[0, 1].set_yticklabels(unq_teams)\n",
        "\n",
        "\n",
        "# Plot 4: World Cup vs Non World Cup away-conceded-avg\n",
        "axs[1, 1].barh([y - width/2 for y in y], wc_scoring['away_conceded_avg'], width, label='World Cup', color='#D4AF37') \n",
        "axs[1, 1].barh([y + width/2 for y in y], non_wc_scoring['away_conceded_avg'], width, label='Non World Cup', color='#A6A6A6')  \n",
        "axs[1, 1].set_title('Away Conceded ')\n",
        "axs[1, 1].set_xlabel('Avg Points')\n",
        "axs[1, 1].set_yticks(y)\n",
        "axs[1, 1].set_yticklabels(unq_teams)\n",
        "          \n",
        "# Create invisible artist in center\n",
        "fig.patches.extend([plt.Rectangle((0.5, 0.5), 0.01, 0.01, \n",
        "                                alpha=0, zorder=100,\n",
        "                                transform=fig.transFigure)])\n",
        "\n",
        "# Create unified legend\n",
        "legend_elements = [\n",
        "    plt.Rectangle((0,0), 1, 1, fc='#D4AF37', ec='#B8860B', lw=1, label='WC'),\n",
        "    plt.Rectangle((0,0), 1, 1, fc='#A6A6A6', ec='#808080', lw=1, label='Non WC')\n",
        "]\n",
        "\n",
        "# Place legend in absolute center\n",
        "legend = fig.legend(handles=legend_elements,\n",
        "                   loc='center',\n",
        "                   bbox_to_anchor=(0.60, 0.49),  # Dead center\n",
        "                   bbox_transform=fig.transFigure,\n",
        "                   frameon=True,\n",
        "                   title='Match Type',\n",
        "                   borderaxespad=1)\n",
        "\n",
        "plt.tight_layout(rect=[0.07, 0.0, 1, 1]) # Adjusts spacing between subplots\n",
        "plt.subplots_adjust(wspace=0.6, hspace=0.6) \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "198b9322",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Year-wise Win Percentage Trends**\n",
        "- Shows **consistency and peaks** for contenders like **NZ, RSA, and IRE**.\n",
        "- Allows modeling team form trajectory over time.\n"
      ],
      "id": "61107591"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#only kees the year, awayWin, homeWin, and country\n",
        "year_wise = rugbyDF[[\"home_team\",\"away_team\",\"homeWin\",\"awayWin\",\"count\",\"year\"]]\n",
        "\n",
        "#drops the away in homeDf and home in awayDf\n",
        "home_year_wise = year_wise.drop(columns={\"away_team\",\"awayWin\"})\n",
        "away_year_wise = year_wise.drop(columns={\"home_team\",\"homeWin\"})\n",
        "\n",
        "#renames so that both df have the same col names for concatenation\n",
        "home_year_wise = home_year_wise.rename(columns={\"home_team\":\"team\",\"homeWin\":\"win\"})\n",
        "away_year_wise = away_year_wise.rename(columns={\"away_team\":\"team\",\"awayWin\":\"win\"})\n",
        "year_wise = pd.concat([home_year_wise,away_year_wise], axis=0).reset_index(drop=True)\n",
        "\n",
        "#groups the data by year and by team and then cerates a win% col for normalized results\n",
        "def getGroupedYW(year_wise):\n",
        "  year_wise_grouped = year_wise.groupby([\"team\",\"year\"]).sum()\n",
        "  year_wise_grouped[\"win_%\"] = year_wise_grouped[\"win\"].div(year_wise_grouped[\"count\"])*100\n",
        "  year_wise_grouped = year_wise_grouped.drop(columns={\"win\",\"count\"})\n",
        "  return year_wise_grouped\n",
        "\n",
        "year_wise_grouped = getGroupedYW(year_wise)"
      ],
      "id": "e017be80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def plotYearWiseData(year_wise_grouped):\n",
        "  year_wise_grouped_reset = year_wise_grouped.reset_index()\n",
        "\n",
        "  plt.figure(figsize=(7.5, 5))\n",
        "  sns.lineplot(data=year_wise_grouped_reset, x='year', y='win_%', hue='team', \n",
        "             style='team', markers=True, dashes=False)\n",
        "\n",
        "  plt.title('Win Percentage by Team Over the Years')\n",
        "  plt.xlabel('Year')\n",
        "  plt.ylabel('Win Percentage')\n",
        "  plt.legend(bbox_to_anchor=(1.001, 1), loc='upper left')\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "plotYearWiseData(year_wise_grouped)"
      ],
      "id": "64a6e327",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since this plot is chaotic, I will cut down on the number of countries plotted. 2 plots with 5 countries on each.\n"
      ],
      "id": "b84d5197"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Split teams into two halves\n",
        "half_idx = len(unq_teams) // 2\n",
        "first_half_teams = unq_teams[:half_idx]\n",
        "second_half_teams = unq_teams[half_idx:]\n",
        "\n",
        "# Create filtered DataFrames\n",
        "df_first_half = year_wise[year_wise['team'].isin(first_half_teams)]\n",
        "df_second_half = year_wise[year_wise['team'].isin(second_half_teams)]\n",
        "\n",
        "#Checking if the teams do not overlap\n",
        "df_first_half[\"team\"].unique()\n",
        "df_second_half[\"team\"].unique()"
      ],
      "id": "02448a74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#uses the function to create the grouped data\n",
        "first_half_grouped = getGroupedYW(df_first_half)\n",
        "\n",
        "#plots it\n",
        "plotYearWiseData(first_half_grouped)"
      ],
      "id": "c614ab3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this breakdown of ARG, AUS, ENG, FRA, and IRE we can see that Australia starts out really strong at the turn of the millennium and slowly starts to regress. 2023 saw them experience their worst year with no wins to show for. IRE and FRA have been the two teams that continue to improve on average. ENG and ARG are the two wildcard teams that can be either really good or really bad; they are wildly unpredictable.\n"
      ],
      "id": "a29e57cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#uses the function to create the grouped data\n",
        "second_half_grouped = getGroupedYW(df_second_half)\n",
        "\n",
        "#plots it\n",
        "plotYearWiseData(second_half_grouped)"
      ],
      "id": "5f85d656",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Modeling Approach**\n",
        "\n",
        "---\n",
        "\n",
        "#### **XGBoost CLassifier with Monte Carlo Simulations**\n",
        "XGBoost (Extreme Gradient Boosting) is a highly efficient and scalable machine learning algorithm, especially for structured/tabular data. Its advantages include:\n",
        "\n",
        "- High Predictive Accuracy: Often outperforms other algorithms (like logistic regression, random forests, or neural networks) on structured datasets.\n",
        "\n",
        "- Handles Non-Linearity & Complex Relationships: Captures intricate patterns in data that simpler models might miss.\n",
        "\n",
        "- Feature Importance: Provides insights into which variables most influence predictions.\n",
        "\n",
        "- Robust to Overfitting: Includes regularization (L1/L2) and early stopping.\n",
        "\n",
        "- Works Well with Imbalanced Data: Can handle classification tasks where one class is rare (e.g., fraud detection).\n",
        "\n",
        "Monte Carlo (MC) simulations are used to model uncertainty and probabilistic outcomes by running thousands of random simulations. When combined with XGBoost, they help:\n",
        "\n",
        "- Quantify Uncertainty: XGBoost gives a point prediction (e.g., probability of an event), but MC can simulate how reliable that prediction is under varying conditions.\n",
        "\n",
        "- Risk Assessment: If inputs have randomness (e.g., stock prices, sensor noise), MC can propagate this uncertainty through the XGBoost model.\n",
        "\n",
        "- Sensitivity Analysis: Test how small changes in input variables affect the output (e.g., \"What if Feature X varies by ±10%?\").\n",
        "\n",
        "- Decision-Making Under Uncertainty: Useful in finance (portfolio risk), healthcare (treatment outcomes), or engineering (system failures).\n",
        "\n",
        "**Full Model Performance**"
      ],
      "id": "3d85464f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data/rugby.csv')\n",
        "df['year'] = df['date'].str[0:4].astype(int)\n",
        "df = df[df.year > 1998]\n",
        "# Data preprocessing\n",
        "# Filter to only international matches (remove club matches)\n",
        "international_matches = df['competition'].str.contains('International|Championship|Nations|World Cup|Test Match', na=False)\n",
        "df = df.loc[international_matches].copy()\n",
        "\n",
        "# Feature engineering\n",
        "# Create target variable - winner of each match\n",
        "conditions = [\n",
        "    df['home_score'] > df['away_score'],\n",
        "    df['home_score'] < df['away_score']\n",
        "]\n",
        "choices = [df['home_team'], df['away_team']]\n",
        "df.loc[:, 'winner'] = np.select(conditions, choices, default='Draw')\n",
        "\n",
        "# Remove draws for classification\n",
        "df = df.loc[df['winner'] != 'Draw'].copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "df.loc[:, 'home_team_encoded'] = le.fit_transform(df['home_team'])\n",
        "df.loc[:, 'away_team_encoded'] = le.transform(df['away_team'])\n",
        "df.loc[:, 'winner_encoded'] = le.transform(df['winner'])\n",
        "\n",
        "# Create features based on historical performance\n",
        "def calculate_team_stats(df):\n",
        "    team_stats = defaultdict(lambda: {'games': 0, 'wins': 0, 'points_for': 0, 'points_against': 0})\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        home_team = row['home_team']\n",
        "        away_team = row['away_team']\n",
        "        home_score = row['home_score']\n",
        "        away_score = row['away_score']\n",
        "        \n",
        "        # Update home team stats\n",
        "        team_stats[home_team]['games'] += 1\n",
        "        team_stats[home_team]['points_for'] += home_score\n",
        "        team_stats[home_team]['points_against'] += away_score\n",
        "        team_stats[home_team]['wins'] += 1 if home_score > away_score else 0\n",
        "        \n",
        "        # Update away team stats\n",
        "        team_stats[away_team]['games'] += 1\n",
        "        team_stats[away_team]['points_for'] += away_score\n",
        "        team_stats[away_team]['points_against'] += home_score\n",
        "        team_stats[away_team]['wins'] += 1 if away_score > home_score else 0\n",
        "    \n",
        "    return team_stats\n",
        "\n",
        "# Calculate rolling stats\n",
        "team_stats = calculate_team_stats(df)\n",
        "\n",
        "# Add features to dataframe\n",
        "def add_features(df, team_stats):\n",
        "    df = df.copy()\n",
        "    df.loc[:, 'home_win_pct'] = df['home_team'].apply(\n",
        "        lambda x: team_stats[x]['wins'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0.5)\n",
        "    df.loc[:, 'away_win_pct'] = df['away_team'].apply(\n",
        "        lambda x: team_stats[x]['wins'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0.5)\n",
        "    df.loc[:, 'home_points_avg'] = df['home_team'].apply(\n",
        "        lambda x: team_stats[x]['points_for'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0)\n",
        "    df.loc[:, 'away_points_avg'] = df['away_team'].apply(\n",
        "        lambda x: team_stats[x]['points_for'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0)\n",
        "    df.loc[:, 'home_points_against_avg'] = df['home_team'].apply(\n",
        "        lambda x: team_stats[x]['points_against'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0)\n",
        "    df.loc[:, 'away_points_against_avg'] = df['away_team'].apply(\n",
        "        lambda x: team_stats[x]['points_against'] / team_stats[x]['games'] if team_stats[x]['games'] > 0 else 0)\n",
        "    \n",
        "    # Add some interaction features\n",
        "    df.loc[:, 'win_pct_diff'] = df['home_win_pct'] - df['away_win_pct']\n",
        "    df.loc[:, 'points_diff'] = df['home_points_avg'] - df['away_points_avg']\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = add_features(df, team_stats)"
      ],
      "id": "641691d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Split into features and target\n",
        "feature_cols = ['home_team_encoded', 'away_team_encoded', \n",
        "                'home_win_pct', 'away_win_pct', \n",
        "                'home_points_avg', 'away_points_avg',\n",
        "                'home_points_against_avg', 'away_points_against_avg',\n",
        "                'win_pct_diff', 'points_diff']\n",
        "X = df.loc[:, feature_cols]\n",
        "y = df.loc[:, 'winner_encoded']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost model\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(le.classes_),\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n",
        "#print(\"Balanced Accuracy accounts for the domination by the top tier 1 teams\")\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))"
      ],
      "id": "a071cc6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Monte Carlo simulation for World Cup prediction\n",
        "def simulate_world_cup(teams, model, le, n_simulations=1000):\n",
        "    # Get current top teams (from our dataset)\n",
        "    top_teams = ['New Zealand', 'South Africa', 'Australia', 'England', 'France', \n",
        "                 'Ireland', 'Wales', 'Scotland', 'Argentina', 'Italy']\n",
        "    \n",
        "    # Create a dictionary to store win counts\n",
        "    win_counts = {team: 0 for team in top_teams}\n",
        "    \n",
        "    for _ in range(n_simulations):\n",
        "        # Randomly select 2 teams to \"play\" in the final\n",
        "        finalists = random.sample(top_teams, 2)\n",
        "        team1, team2 = finalists\n",
        "        \n",
        "        # Create feature vector for this matchup\n",
        "        try:\n",
        "            team1_encoded = le.transform([team1])[0]\n",
        "            team2_encoded = le.transform([team2])[0]\n",
        "        except ValueError:\n",
        "            # Skip if team not in our training data\n",
        "            continue\n",
        "            \n",
        "        # Get team stats (simplified - in practice you'd want more recent stats)\n",
        "        team1_stats = team_stats.get(team1, {'games': 1, 'wins': 0, 'points_for': 0, 'points_against': 0})\n",
        "        team2_stats = team_stats.get(team2, {'games': 1, 'wins': 0, 'points_for': 0, 'points_against': 0})\n",
        "        \n",
        "        # Create feature row\n",
        "        features = np.array([\n",
        "            team1_encoded, team2_encoded,\n",
        "            team1_stats['wins'] / max(1, team1_stats['games']),\n",
        "            team2_stats['wins'] / max(1, team2_stats['games']),\n",
        "            team1_stats['points_for'] / max(1, team1_stats['games']),\n",
        "            team2_stats['points_for'] / max(1, team2_stats['games']),\n",
        "            team1_stats['points_against'] / max(1, team1_stats['games']),\n",
        "            team2_stats['points_against'] / max(1, team2_stats['games']),\n",
        "            (team1_stats['wins'] / max(1, team1_stats['games'])) - \n",
        "            (team2_stats['wins'] / max(1, team2_stats['games'])),\n",
        "            (team1_stats['points_for'] / max(1, team1_stats['games'])) - \n",
        "            (team2_stats['points_for'] / max(1, team2_stats['games']))\n",
        "        ]).reshape(1, -1)\n",
        "        \n",
        "        # Predict probabilities\n",
        "        try:\n",
        "            probs = model.predict_proba(features)[0]\n",
        "            \n",
        "            # Sample winner based on probabilities\n",
        "            winner_idx = np.random.choice(len(probs), p=probs)\n",
        "            winner = le.inverse_transform([winner_idx])[0]\n",
        "            \n",
        "            if winner in win_counts:\n",
        "                win_counts[winner] += 1\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    # Convert counts to percentages\n",
        "    total = max(1, sum(win_counts.values()))\n",
        "    win_pct = {team: (count / total) * 100 for team, count in win_counts.items()}\n",
        "    \n",
        "    return win_pct\n",
        "\n",
        "# Run simulation\n",
        "win_probabilities = simulate_world_cup(le.classes_, model, le, n_simulations=1000)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nPredicted 2027 Rugby World Cup Win Probabilities:\")\n",
        "for team, prob in sorted(win_probabilities.items(), key=lambda x: x[1], reverse=True):\n",
        "    if prob > 0:\n",
        "        print(f\"{team}: {prob:.1f}%\")"
      ],
      "id": "c77e1e66",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XGBoost provides these importance types by default:\n",
        "\n",
        "- weight: The number of times a feature appears in a tree\n",
        "\n",
        "- gain: The average gain of splits which use the feature\n",
        "\n",
        "- cover: The average coverage of splits which use the feature\n"
      ],
      "id": "26bea4e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# For 'gain' or 'cover' importance\n",
        "importance_types = ['weight', 'gain', 'cover']\n",
        "for imp_type in importance_types:\n",
        "    print(f\"\\n{imp_type} importance:\")\n",
        "    importance = model.get_booster().get_score(importance_type=imp_type)\n",
        "    print(importance)\n",
        "    \n",
        "    # Plot\n",
        "    xgb.plot_importance(model, importance_type=imp_type)\n",
        "    plt.title(f'{imp_type} importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "8435adaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Weight is the number of times that feature appears in a tree**\n",
        "Interpretation\n",
        "\n",
        "- win_pct_diff was used in 632 splits across all trees.\n",
        "\n",
        "This is simple and easy to compute but it doesn't account for the overall impact towards the model performance. The number of times a feature appears does not explain how much the model improves by.\n",
        "\n",
        "\n",
        "**Gain is the average improvement in the model accuracy (Gini impurity for classification)**\n",
        "Interpretation\n",
        "\n",
        "- A gain of 1.78 means away_win_pct, on average, improves class separation by 1.78 units per split.\n",
        "\n",
        "Directly measures feature usefulness, but it can be biased toward continuous features (they often allow more fine-grained splits).\n",
        "\n",
        "**Cover is the average number of samples impacted by splits using a feature**\n",
        "Interpretation\n",
        "\n",
        "- win_pct_diff 18.25238 means splits using this feature affect ~18.25238 samples on average.\n",
        "\n",
        "Cover helps detect broadly influential features, but it doesn’t directly measure predictive power.\n",
        "\n",
        "####Feature Selection and Model Optimization"
      ],
      "id": "cb42ac13"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#will use the top 5 gain features for the revised model\n",
        "top_features = ['home_points_against_avg', 'away_points_against_avg', 'home_win_pct','home_team_encoded','away_win_pct']  \n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "# Re-train the model\n",
        "model_top = xgb.XGBClassifier(\n",
        "  objective='multi:softprob',\n",
        "    num_class=len(le.classes_),\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "model_top.fit(X_train_top, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred_top = model_top.predict(X_test_top)\n",
        "accuracy1 = accuracy_score(y_test, y_pred_top)\n",
        "print(f\"Refined Model accuracy: {accuracy1:.2f}\")\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_top))"
      ],
      "id": "191a396e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the model performs almost identically to the one from before. Since it is simpler and the performance is nearly identical, we will go ahead and perform cross validation to find optimal hyper-parameters.\n"
      ],
      "id": "1571cc9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_depth': [ 5],          # Control tree complexity\n",
        "    'learning_rate': [0.01], # Smaller rates for high-gain features\n",
        "    'n_estimators': [50],   # More trees to leverage strong features\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model_top, params, cv=2, scoring='f1_macro')\n",
        "grid.fit(X_train_top, y_train)\n",
        "print(f\"Best params: {grid.best_params_}\")"
      ],
      "id": "e34c8e4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# The best model is already refit and stored in `grid.best_estimator_`\n",
        "best_model = grid.best_estimator_\n",
        "print(best_model)\n",
        "# Evaluate on test data\n",
        "y_pred_best = best_model.predict(X_test_top)\n",
        "accuracy2 = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"Optimized Model accuracy: {accuracy2:.2f}\")\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_best))"
      ],
      "id": "a44c186c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best params do not make much of a difference as the accuracy and balanced accuracy stayed pretty much the same.\n",
        "\n",
        "Revised Monte Carlo Simulations definition with world cup stages"
      ],
      "id": "837f68fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def enhanced_world_cup_simulation(teams, model, le, team_stats, n_simulations=1000):\n",
        "    win_counts = {team: 0 for team in teams}\n",
        "    \n",
        "    for _ in range(n_simulations):\n",
        "        # Simulate a more realistic tournament structure\n",
        "        quarterfinalists = random.sample(teams, 8)\n",
        "        \n",
        "        # Simulate knockout stages - FIXED to use model predictions\n",
        "        semifinalists = []\n",
        "        for i in range(0, 8, 2):\n",
        "            team1, team2 = quarterfinalists[i], quarterfinalists[i+1]\n",
        "            winner = predict_winner(team1, team2, model, le, team_stats)\n",
        "            semifinalists.append(winner)\n",
        "        \n",
        "        finalists = []\n",
        "        for i in range(0, 4, 2):\n",
        "            team1, team2 = semifinalists[i], semifinalists[i+1]\n",
        "            winner = predict_winner(team1, team2, model, le, team_stats)\n",
        "            finalists.append(winner)\n",
        "        \n",
        "        # Predict final match\n",
        "        team1, team2 = finalists\n",
        "        winner = predict_winner(team1, team2, model, le, team_stats)\n",
        "        \n",
        "        if winner in win_counts:\n",
        "            win_counts[winner] += 1\n",
        "    \n",
        "    # Convert to percentages\n",
        "    total = max(1, sum(win_counts.values()))\n",
        "    return {team: (count/total)*100 for team, count in win_counts.items()}\n",
        "\n",
        "def predict_winner(team1, team2, model, le, team_stats):\n",
        "    try:\n",
        "        # Create feature vector - MUST MATCH YOUR MODEL'S TRAINING FEATURES\n",
        "        features = np.array([\n",
        "            team_stats.get(team1, {}).get('points_against_avg', 0),  # home_points_against_avg\n",
        "            team_stats.get(team2, {}).get('points_against_avg', 0),  # away_points_against_avg\n",
        "            team_stats.get(team1, {}).get('win_pct', 0.5),           # home_win_pct\n",
        "            le.transform([team1])[0],                                 # home_team_encoded\n",
        "            team_stats.get(team2, {}).get('win_pct', 0.5)             # away_win_pct\n",
        "        ]).reshape(1, -1)\n",
        "        \n",
        "        # Verify feature count matches model\n",
        "        assert features.shape[1] == model.n_features_in_\n",
        "        \n",
        "        probs = model.predict_proba(features)[0]\n",
        "        winner_idx = np.random.choice(len(probs), p=probs)\n",
        "        return le.inverse_transform([winner_idx])[0]\n",
        "    except Exception as e:\n",
        "        # Fallback to random choice if prediction fails\n",
        "        print(f\"Prediction failed for {team1} vs {team2}: {e}\")\n",
        "        return random.choice([team1, team2])"
      ],
      "id": "6e17eec6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "top_teams = [\n",
        "    'New Zealand', 'South Africa', 'Australia', \n",
        "    'England', 'France', 'Ireland', \n",
        "    'Wales', 'Scotland', 'Argentina', 'Italy'\n",
        "]\n",
        "\n",
        "print(\"\\nRunning enhanced simulation...\")\n",
        "win_probs = enhanced_world_cup_simulation(\n",
        "    top_teams, \n",
        "    best_model, \n",
        "    le, \n",
        "    team_stats,  \n",
        "    n_simulations=10000\n",
        ")\n",
        "\n",
        "# Display results again\n",
        "print(\"\\nPredicted 2027 Rugby World Cup Win Probabilities with Optimized Model:\")\n",
        "for team, prob in sorted(win_probs.items(), key=lambda x: x[1], reverse=True):\n",
        "    if prob > 0:\n",
        "        print(f\"{team}: {prob:.1f}%\")"
      ],
      "id": "96fd986f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interestingly, after creating a model that prioritizes the top features while avoiding comprimising performance, New Zealand now slips to 7th. This could be because of the way the features appear in the forest and how those features favor England.\n",
        "\n",
        "Maybe the next steps could be uncovering the exact reasons as to this change.\n",
        "\n",
        "####What we would do differently next time\n",
        "\n",
        "- One of the primary areas for improvement lies in the depth and clarity of our predictive modeling approach. Although we used XGBoost as a classifier, the report lacked detailed documentation of the modeling pipeline. Important elements such as the definition of the target variable, the rationale for selecting input features, and performance metrics (e.g., accuracy, AUC, F1-score) were either underdeveloped or omitted. Without this transparency, it is difficult to gauge the reliability and generalizability of our predictions. \n",
        "-   Another key limitation concerns the treatment of time in our dataset. By aggregating team performance over the entire 25-year period, we risk masking temporal trends that are crucial for forecasting. For example, a team like England may have exhibited peak performance in the early 2000s but declined in later years—averaging across eras erases these nuances. To better capture form and momentum, we recommend segmenting the data into discrete World Cup cycles (e.g., 1999–2002, 2003–2006, etc.) and calculating team-level metrics for each period. This time-aware approach would allow us to assess the predictive power of pre-tournament form on RWC success more accurately.\n",
        "-   Another methodological enhancement would be to implement a more rigorous validation strategy. Rather than predicting the 2027 World Cup in isolation, we could simulate “leave-one-tournament-out” validation. This approach would involve using data from previous cycles to predict each past tournament (e.g., using 1999–2002 data to predict 2003, and so on). Doing so would help test the generalizability of our models across different eras and improve confidence in our forecasting methodology.\n"
      ],
      "id": "247c2fa7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}